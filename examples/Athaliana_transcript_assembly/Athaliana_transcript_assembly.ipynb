{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of *A. thaliana* RNA-Seq data with pyrpipe \n",
    "Use A thaliana public RNA-Seq data to assemble transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mLogs will be saved to 2020-01-29-12_00_45_pyrpipe.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyrpipe import sra,mapping,assembly,qc,tools\n",
    "from pyrpipe import pyrpipe_utils as pu\n",
    "from pyrpipe import pyrpipe_engine as pe\n",
    "#First get the srr accessions of the runs. For this one can use the python package pysradb or R package sradb\n",
    "#i will consider following randomly selected accessions\n",
    "#athalRuns=['SRR976159','SRR978411','SRR978410','SRR971778','SRR1058116','SRR1058118','SRR1058121','SRR1058110','SRR1058120','SRR1058117','SRR1104134','SRR1104133','SRR1104135','SRR1104136','SRR1105825']\n",
    "athalRunsSmol=['SRR976159','SRR978411','SRR971778']\n",
    "#set your working directory if you don't want to use the current working directory\n",
    "workingDir=\"athal_out\"\n",
    "#create working directory\n",
    "if not pu.check_paths_exist(workingDir):\n",
    "    pu.mkdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download genome and gtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GENOME=workingDir+\"/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa\"\n",
    "GTF=workingDir+\"/Arabidopsis_thaliana.TAIR10.45.gtf\"\n",
    "\n",
    "if not pu.check_files_exist(GENOME):\n",
    "    print(\"Downloading genome fasta file\")\n",
    "    wget=\"wget ftp://ftp.ensemblgenomes.org/pub/release-46/plants/fasta/arabidopsis_thaliana/dna/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz -q -O \"+GENOME+\".gz\"\n",
    "    pe.execute_command(wget.split(),verbose=True,logs=False)\n",
    "    pe.execute_command(['gunzip',GENOME+\".gz\"],verbose=True,logs=False)\n",
    "    \n",
    "if not pu.check_files_exist(GTF):\n",
    "    print(\"Downloading GTF file\")\n",
    "    wget=\"wget ftp://ftp.ensemblgenomes.org/pub/release-46/plants/gtf/arabidopsis_thaliana/Arabidopsis_thaliana.TAIR10.46.gtf.gz -O \"+GTF+\".gz\"\n",
    "    pe.execute_command(wget.split(),verbose=True,logs=False)\n",
    "    pe.execute_command(['gunzip',GTF+\".gz\"],verbose=True,logs=False)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and create SRA objects\n",
    "First we can download all data to disk and create pyrpipe.SRA objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95mDownloading SRR976159 ...\u001b[0m\n",
      "\u001b[94m$ prefetch -O athal_out/SRR976159 SRR976159\u001b[0m\n",
      "\u001b[92mTime taken:0:00:12\u001b[0m\n",
      "Downloaded file: athal_out/SRR976159/SRR976159.sra 381.9 MB \n",
      "\u001b[95mDownloading SRR978411 ...\u001b[0m\n",
      "\u001b[94m$ prefetch -O athal_out/SRR978411 SRR978411\u001b[0m\n",
      "\u001b[92mTime taken:0:00:09\u001b[0m\n",
      "Downloaded file: athal_out/SRR978411/SRR978411.sra 347.2 MB \n",
      "\u001b[95mDownloading SRR971778 ...\u001b[0m\n",
      "\u001b[94m$ prefetch -O athal_out/SRR971778 SRR971778\u001b[0m\n",
      "\u001b[92mTime taken:0:00:11\u001b[0m\n",
      "Downloaded file: athal_out/SRR971778/SRR971778.sra 434.4 MB \n",
      "Following runs downloaded:\n",
      "SRR976159\n",
      "SRR978411\n",
      "SRR971778\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##download all data in athalRuns\n",
    "sraObjects=[]\n",
    "\n",
    "for x in athalRunsSmol:\n",
    "    thisSraOb=sra.SRA(x,workingDir)\n",
    "    if thisSraOb.download_sra():\n",
    "        sraObjects.append(thisSraOb)\n",
    "    else:\n",
    "        print(\"Download failed:\"+x)\n",
    "\n",
    "#NOTE: To download fastq directly, instaead of .sra, one can use the download_fastq() method\n",
    "print(\"Following runs downloaded:\")\n",
    "for ob in sraObjects:\n",
    "    print(ob.srr_accession)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving current session\n",
    "A reason why I have first downloaded the SRA files is that **in a typical HPC setting, one might have access to special data-transfer nodes**. These nodes could be used for downloading data efficiently but does not allow expensive computations. On the other hand data could also be downloaded from compute nodes **but you will burn most of your computing time/allocations for only downloading the data**. Thus it might be a good idea to download data separately and then start the processing.\n",
    "\n",
    "We can save the objects created with pyrpipe and restore our session later on a compute node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save current session\n",
    "from pyrpipe import pyrpipe_session\n",
    "pyrpipe_session.save_session(filename=\"mySession\",add_timestamp=True,out_dir=workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restoring saved session\n",
    "We can restore the pyrpipe session using the saved session file (saved with .pyrpipe extension).\n",
    "\n",
    "**Note** After restoring session a new log file will generated to store the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first clear current session used by notebook\n",
    "%reset\n",
    "print(sraObjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restore session\n",
    "from pyrpipe import pyrpipe_session\n",
    "#update the pyrpipe session file below\n",
    "pyrpipe_session.restore_session(\"athal_out/mySession_20200129112604.pyrpipe\")\n",
    "print(sraObjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing sra files\n",
    " \n",
    " After restoring session we can proceed. So far we have downloaded data the sra files and sraObjects contsins all the SRA objects coressponding to each SRR Accession.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert sra to fastq file\n",
    "We can convert .sra files to .fastq. Using ```delete_sra=True``` will delete the downloaded sra file from disk. Note the second argument ```**{\"-e\":\"8\",\"-f\":\"\",\"-t\":workingDir}``` is basically a dict containing additional fasterq-dump parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m$ fasterq-dump -e 8 -f -t athal_out -O athal_out/SRR976159 -o SRR976159.fastq athal_out/SRR976159/SRR976159.sra\u001b[0m\n",
      "\u001b[92mTime taken:0:00:14\u001b[0m\n",
      "\u001b[94m$ fasterq-dump -e 8 -f -t athal_out -O athal_out/SRR978411 -o SRR978411.fastq athal_out/SRR978411/SRR978411.sra\u001b[0m\n",
      "\u001b[92mTime taken:0:00:26\u001b[0m\n",
      "\u001b[94m$ fasterq-dump -e 8 -f -t athal_out -O athal_out/SRR971778 -o SRR971778.fastq athal_out/SRR971778/SRR971778.sra\u001b[0m\n",
      "\u001b[92mTime taken:0:00:30\u001b[0m\n",
      "Fastq dump finished for:\n",
      "SRR976159\n",
      "SRR978411\n",
      "SRR971778\n"
     ]
    }
   ],
   "source": [
    "for ob in sraObjects:\n",
    "    ob.run_fasterqdump(delete_sra=True,**{\"-e\":\"8\",\"-f\":\"\",\"-t\":workingDir}) #use 8 threads\n",
    "\n",
    "print(\"Fastq dump finished for:\")\n",
    "for ob in sraObjects:\n",
    "    if ob.fastqFilesExistsLocally():\n",
    "        print(ob.srr_accession)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing fastq quality control\n",
    "After running fasterq-dump, the fastq files will be updated in each SRA object. To perform fastq quality control we can use ```trimgalore``` or ```bbduk.sh```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing QC using bbduk.sh\n",
      "\u001b[94m$ bbduk.sh ktrim=r k=23 mink=11 qtrim='rl' trimq=10 ref=adapters2.fa in=athal_out/SRR976159/SRR976159_1.fastq in2=athal_out/SRR976159/SRR976159_2.fastq out=athal_out/SRR976159/SRR976159_1_bbduk.fastq out2=athal_out/SRR976159/SRR976159_2_bbduk.fastq -Xmx2g\u001b[0m\n",
      "\u001b[92mTime taken:0:00:11\u001b[0m\n",
      "Performing QC using bbduk.sh\n",
      "\u001b[94m$ bbduk.sh ktrim=r k=23 mink=11 qtrim='rl' trimq=10 ref=adapters2.fa in=athal_out/SRR978411/SRR978411_1.fastq in2=athal_out/SRR978411/SRR978411_2.fastq out=athal_out/SRR978411/SRR978411_1_bbduk.fastq out2=athal_out/SRR978411/SRR978411_2_bbduk.fastq -Xmx2g\u001b[0m\n",
      "\u001b[92mTime taken:0:00:32\u001b[0m\n",
      "Performing QC using bbduk.sh\n",
      "\u001b[94m$ bbduk.sh ktrim=r k=23 mink=11 qtrim='rl' trimq=10 ref=adapters2.fa in=athal_out/SRR971778/SRR971778_1.fastq in2=athal_out/SRR971778/SRR971778_2.fastq out=athal_out/SRR971778/SRR971778_1_bbduk.fastq out2=athal_out/SRR971778/SRR971778_2_bbduk.fastq -Xmx2g\u001b[0m\n",
      "\u001b[92mTime taken:0:00:55\u001b[0m\n",
      "SRR Accession: SRR976159, fastq files: athal_out/SRR976159/SRR976159_1_bbduk.fastq. athal_out/SRR976159/SRR976159_2_bbduk.fastq\n",
      "Both files exist!!\n",
      "SRR Accession: SRR978411, fastq files: athal_out/SRR978411/SRR978411_1_bbduk.fastq. athal_out/SRR978411/SRR978411_2_bbduk.fastq\n",
      "Both files exist!!\n",
      "SRR Accession: SRR971778, fastq files: athal_out/SRR971778/SRR971778_1_bbduk.fastq. athal_out/SRR971778/SRR971778_2_bbduk.fastq\n",
      "Both files exist!!\n"
     ]
    }
   ],
   "source": [
    "#using bbduk\n",
    "pathToAdapters=\"adapters2.fa\"\n",
    "#arguments to pass to bbduk\n",
    "bbdOpts={\"ktrim\":\"r\",\"k\":\"23\",\"mink\":\"11\",\"qtrim\":\"'rl'\",\"trimq\":\"10\",\"--\":(\"-Xmx2g\",),\"ref\":pathToAdapters}\n",
    "#an object for running bbduk.sh with specified parameters\n",
    "bbdOb=qc.BBmap(**bbdOpts)\n",
    "#start QC\n",
    "for ob in sraObjects:\n",
    "    ob.perform_qc(bbdOb)\n",
    "    \n",
    "#after finishing view the current fastq files in the sra objects\n",
    "\n",
    "for ob in sraObjects:\n",
    "    print(\"SRR Accession: {}, fastq files: {}. {}\".format(ob.srr_accession,ob.localfastq1Path,ob.localfastq2Path))\n",
    "    \n",
    "    if ob.fastqFilesExistsLocally():\n",
    "          print(\"Both files exist!!\")\n",
    "    else:\n",
    "          print(\"Error\")\n",
    "          raise Exception(\"Fastq files not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning clean reads to the reference genome\n",
    "After finishing fastq quality control we will map reads to the reference genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Hisat2 index provided. Please build index now to generate an index using build_Index()....\n"
     ]
    }
   ],
   "source": [
    "#using hisat2\n",
    "hsOpts={\"--dta-cufflinks\":\"\",\"-p\":\"8\"}\n",
    "hs=mapping.Hisat2(hisat2_index=\"\",**hsOpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building hisat index...\n",
      "\u001b[94m$ hisat2-build -p 8 -a -q athal_out/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa athal_out/athalIndex/athalInd\u001b[0m\n",
      "\u001b[92mTime taken:0:00:37\u001b[0m\n",
      "Indexing done.\n",
      "Index athal_out/athalIndex/athalInd exists\n"
     ]
    }
   ],
   "source": [
    "#We can build hisat2 index if one doesnt already exist. This index will be bound to the Hisat2 object, hs.\n",
    "hisat2_buildArgs={\"-p\":\"8\",\"-a\":\"\",\"-q\":\"\"}\n",
    "#start building\n",
    "#parameters are out directory, index name, reference genome\n",
    "if hs.build_index(workingDir+\"/athalIndex\",\"athalInd\",GENOME,**hisat2_buildArgs) :\n",
    "    print(\"Indexing done.\")\n",
    "    \n",
    "#check the index present in hisat2 object\n",
    "if hs.check_index():\n",
    "    print(\"Index {} exists\".format(hs.hisat2_index))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SRR976159...\n",
      "\u001b[94m$ hisat2 --dta-cufflinks -p 10 -x athal_out/athalIndex/athalInd -1 athal_out/SRR976159/SRR976159_1_bbduk.fastq -2 athal_out/SRR976159/SRR976159_2_bbduk.fastq -S athal_out/SRR976159/SRR976159_hisat2.sam\u001b[0m\n",
      "\u001b[92mTime taken:0:01:05\u001b[0m\n",
      "Processing SRR978411...\n",
      "\u001b[94m$ hisat2 --dta-cufflinks -p 10 -x athal_out/athalIndex/athalInd -1 athal_out/SRR978411/SRR978411_1_bbduk.fastq -2 athal_out/SRR978411/SRR978411_2_bbduk.fastq -S athal_out/SRR978411/SRR978411_hisat2.sam\u001b[0m\n",
      "\u001b[92mTime taken:0:01:07\u001b[0m\n",
      "Processing SRR971778...\n",
      "\u001b[94m$ hisat2 --dta-cufflinks -p 10 -x athal_out/athalIndex/athalInd -1 athal_out/SRR971778/SRR971778_1_bbduk.fastq -2 athal_out/SRR971778/SRR971778_2_bbduk.fastq -S athal_out/SRR971778/SRR971778_hisat2.sam\u001b[0m\n",
      "\u001b[92mTime taken:0:01:17\u001b[0m\n",
      "Alignment done!! Sam files:athal_out/SRR976159/SRR976159_hisat2.sam,athal_out/SRR978411/SRR978411_hisat2.sam,athal_out/SRR971778/SRR971778_hisat2.sam\n"
     ]
    }
   ],
   "source": [
    "#start alignment\n",
    "samList=[]\n",
    "for ob in sraObjects:\n",
    "    print(\"Processing {}...\".format(ob.srr_accession))\n",
    "    thisSam=hs.perform_alignment(ob,**{\"-p\":\"10\"}) #note parametrs supplied here will replace existing parameters passed during object construction\n",
    "    if thisSam:\n",
    "        samList.append(thisSam)\n",
    "print(\"Alignment done!! Sam files:\"+ \",\".join(samList))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using samtools\n",
    "```pyrpipe``` implemnts a basic high-level samtools API through which samtools functionality could be accessed. Note that users can also use the library ```pysam``` to get advance SAM/BAM/VCF/BCF functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:athal_out/SRR976159/SRR976159_hisat2.sam\n",
      "\u001b[94m$ samtools view -@ 8 -o athal_out/SRR976159/SRR976159_hisat2.bam -b athal_out/SRR976159/SRR976159_hisat2.sam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:33\u001b[0m\n",
      "\u001b[94m$ samtools sort -@ 8 -o athal_out/SRR976159/SRR976159_hisat2_sorted.bam athal_out/SRR976159/SRR976159_hisat2.bam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:20\u001b[0m\n",
      "Processing:athal_out/SRR978411/SRR978411_hisat2.sam\n",
      "\u001b[94m$ samtools view -@ 8 -o athal_out/SRR978411/SRR978411_hisat2.bam -b athal_out/SRR978411/SRR978411_hisat2.sam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:24\u001b[0m\n",
      "\u001b[94m$ samtools sort -@ 8 -o athal_out/SRR978411/SRR978411_hisat2_sorted.bam athal_out/SRR978411/SRR978411_hisat2.bam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:18\u001b[0m\n",
      "Processing:athal_out/SRR971778/SRR971778_hisat2.sam\n",
      "\u001b[94m$ samtools view -@ 8 -o athal_out/SRR971778/SRR971778_hisat2.bam -b athal_out/SRR971778/SRR971778_hisat2.sam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:30\u001b[0m\n",
      "\u001b[94m$ samtools sort -@ 8 -o athal_out/SRR971778/SRR971778_hisat2_sorted.bam athal_out/SRR971778/SRR971778_hisat2.bam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:24\u001b[0m\n",
      "Sorted bam files:athal_out/SRR976159/SRR976159_hisat2_sorted.bam,athal_out/SRR978411/SRR978411_hisat2_sorted.bam,athal_out/SRR971778/SRR971778_hisat2_sorted.bam\n"
     ]
    }
   ],
   "source": [
    "samOb=tools.Samtools(**{\"-@\":\"8\"})\n",
    "#sam to sorted bam\n",
    "bamList=[]\n",
    "i=0\n",
    "for sam in samList:\n",
    "    print(\"Processing:\"+sam)\n",
    "    thisBam=samOb.sam_sorted_bam(sam,delete_sam=True,delete_bam=True,objectid=sraObjects[i].srr_accession) #add the object id to keep track of process and object. helpful in debugging and reports later\n",
    "    i+=1\n",
    "    if thisBam:\n",
    "        bamList.append(thisBam)\n",
    "print(\"Sorted bam files:\"+\",\".join(bamList))\n",
    "\n",
    "###Some Examples using pysam###\n",
    "#for details see: https://pysam.readthedocs.io/en/latest/\n",
    "#import pysam\n",
    "#pysam.sort(\"-@\",\"8\",\"-o\",\"sortedBam.bam\",\"in.bam)\n",
    "#pysam.merge(\"-@\",\"8\",\"myMerge\",*bamList,\"-f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcript assembly\n",
    "We can use stringtie to perform transcript assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:athal_out/SRR976159/SRR976159_hisat2_sorted.bam\n",
      "\u001b[94m$ stringtie -G athal_out/Arabidopsis_thaliana.TAIR10.45.gtf -o athal_out/SRR976159/SRR976159_hisat2_sorted_stringtie.gtf athal_out/SRR976159/SRR976159_hisat2_sorted.bam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:40\u001b[0m\n",
      "Processing:athal_out/SRR978411/SRR978411_hisat2_sorted.bam\n",
      "\u001b[94m$ stringtie -G athal_out/Arabidopsis_thaliana.TAIR10.45.gtf -o athal_out/SRR978411/SRR978411_hisat2_sorted_stringtie.gtf athal_out/SRR978411/SRR978411_hisat2_sorted.bam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:36\u001b[0m\n",
      "Processing:athal_out/SRR971778/SRR971778_hisat2_sorted.bam\n",
      "\u001b[94m$ stringtie -G athal_out/Arabidopsis_thaliana.TAIR10.45.gtf -o athal_out/SRR971778/SRR971778_hisat2_sorted_stringtie.gtf athal_out/SRR971778/SRR971778_hisat2_sorted.bam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:42\u001b[0m\n",
      "Final GTFs:athal_out/SRR976159/SRR976159_hisat2_sorted_stringtie.gtf,athal_out/SRR978411/SRR978411_hisat2_sorted_stringtie.gtf,athal_out/SRR971778/SRR971778_hisat2_sorted_stringtie.gtf\n"
     ]
    }
   ],
   "source": [
    "st=assembly.Stringtie(reference_gtf=GTF)\n",
    "gtfList=[]\n",
    "i=0\n",
    "for bam in bamList:\n",
    "    print(\"Processing:\"+bam)\n",
    "    gtfList.append(st.perform_assembly(bam,objectid=sraObjects[i].srr_accession))\n",
    "    i+=1\n",
    "\n",
    "print(\"Final GTFs:\"+\",\".join(gtfList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating analysis reports\n",
    "pyrpipe_diagnostic.py lets user generate different types of reports and summaries. Following commands can be run from shell.\n",
    "\n",
    "\n",
    "**Generate a pdf report**\n",
    "```$ pyrpipe_diagnostic.py report pyrpipe_logs/2019-12-24-16_14_55_pyrpipe.log```\n",
    "\n",
    "[Output](https://github.com/urmi-21/pyrpipe/blob/master/examples/Athaliana_transcript_assembly/2019-12-24-16_14_55_pyrpipe.pdf)\n",
    "\n",
    "***Dump all commands to a shell file***\n",
    "```pyrpipe_diagnostic.py shell pyrpipe_logs/2019-12-24-16_14_55_pyrpipe.log```\n",
    "\n",
    "[Output](https://github.com/urmi-21/pyrpipe/blob/master/examples/Athaliana_transcript_assembly/2019-12-24-16_14_55_pyrpipe.sh)\n",
    "\n",
    "\n",
    "**Generate multiqc report**\n",
    "```$ pyrpipe_diagnostic.py multiqc -r pyrpipe_logs/2019-12-24-16_14_55_pyrpipe.log```\n",
    "\n",
    "[Output](https://github.com/urmi-21/pyrpipe/blob/master/examples/Athaliana_transcript_assembly/multiqc_report.html)\n",
    "\n",
    "\n",
    "**Generate runtime benchmarks**\n",
    "```pyrpipe_diagnostic.py benchmark pyrpipe_logs/2019-12-24-16_14_55_pyrpipe.log```\n",
    "\n",
    "[Output](https://github.com/urmi-21/pyrpipe/tree/master/examples/Athaliana_transcript_assembly/tmp/benchmark_reports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
