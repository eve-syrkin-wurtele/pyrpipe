{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mCreating script backup: .pyrpipe/_pyrpipe_b9d1b41b9e44376d98653a33686db164_ipykernel_launcher.py\u001b[0m\n",
      "\u001b[93mLogs will be saved to /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Maize_lncRNA_prediction/pyrpipe_logs/2021-01-01-16_47_00.489627_52103_pyrpipe.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyrpipe import sra,mapping,assembly,qc,tools\n",
    "from pyrpipe import pyrpipe_utils as pu\n",
    "from pyrpipe import pyrpipe_engine as pe\n",
    "#First get the srr accessions of the runs. For this one can use the python package pysradb or R package sradb\n",
    "#runs=['SRR3098746','SRR3098745','SRR3098744'] #from the study SRP068369\n",
    "runs=['SRR765545'] #small test\n",
    "#set up directories\n",
    "\n",
    "workingDir=\"maize_out\"\n",
    "#create working directory\n",
    "if not pu.check_paths_exist(workingDir):\n",
    "    pu.mkdir(workingDir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Genome and GTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading genome fasta file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mStart:21-01-01 16:48:32\u001b[0m\n",
      "\u001b[96m$ wget ftp://ftp.ensemblgenomes.org/pub/release-46/plants/fasta/zea_mays/dna/Zea_mays.B73_RefGen_v4.dna.toplevel.fa.gz -q -O maize_out/Zea_mays.B73_RefGen_v4.dna.toplevel.fa.gz\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 16:48:56\u001b[0m\n",
      "\u001b[92mTime taken:0:00:24\u001b[0m\n",
      "\u001b[93mStart:21-01-01 16:48:56\u001b[0m\n",
      "\u001b[96m$ gunzip maize_out/Zea_mays.B73_RefGen_v4.dna.toplevel.fa.gz\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 16:49:11\u001b[0m\n",
      "\u001b[92mTime taken:0:00:15\u001b[0m\n",
      "\u001b[93mStart:21-01-01 16:49:11\u001b[0m\n",
      "\u001b[96m$ wget ftp://ftp.ensemblgenomes.org/pub/release-46/plants/gtf/zea_mays/Zea_mays.B73_RefGen_v4.46.gtf.gz -q -O maize_out/Zea_mays.B73_RefGen_v4.46.gtf.gz\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GTF file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mEnd:21-01-01 16:49:18\u001b[0m\n",
      "\u001b[92mTime taken:0:00:07\u001b[0m\n",
      "\u001b[93mStart:21-01-01 16:49:18\u001b[0m\n",
      "\u001b[96m$ gunzip maize_out/Zea_mays.B73_RefGen_v4.46.gtf.gz\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 16:49:20\u001b[0m\n",
      "\u001b[92mTime taken:0:00:03\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "GENOME=workingDir+\"/Zea_mays.B73_RefGen_v4.dna.toplevel.fa\"\n",
    "GTF=workingDir+\"/Zea_mays.B73_RefGen_v4.46.gtf\"\n",
    "\n",
    "if not pu.check_files_exist(GENOME):\n",
    "    print(\"Downloading genome fasta file\")\n",
    "    wget=\"wget ftp://ftp.ensemblgenomes.org/pub/release-46/plants/fasta/zea_mays/dna/Zea_mays.B73_RefGen_v4.dna.toplevel.fa.gz -q -O \"+GENOME+\".gz\"\n",
    "    pe.execute_command(wget.split(),verbose=False,logs=False)\n",
    "    pe.execute_command(['gunzip',GENOME+\".gz\"],verbose=False,logs=False)\n",
    "    \n",
    "if not pu.check_files_exist(GTF):\n",
    "    print(\"Downloading GTF file\")\n",
    "    wget=\"wget ftp://ftp.ensemblgenomes.org/pub/release-46/plants/gtf/zea_mays/Zea_mays.B73_RefGen_v4.46.gtf.gz -q -O \"+GTF+\".gz\"\n",
    "    pe.execute_command(wget.split(),verbose=False,logs=False)\n",
    "    pe.execute_command(['gunzip',GTF+\".gz\"],verbose=False,logs=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data, pre-process\n",
    "\n",
    "Similar to the *A. thaliana* example, we will create SRA objects to download the fastq files. Then, we will use `trim_galore` to perform trimming by creatin a `Trimgalore` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mStart:21-01-01 16:53:21\u001b[0m\n",
      "\u001b[96m$ prefetch -O maize_out/SRR765545 SRR765545\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 16:53:28\u001b[0m\n",
      "\u001b[92mTime taken:0:00:08\u001b[0m\n",
      "\u001b[93mStart:21-01-01 16:53:29\u001b[0m\n",
      "\u001b[96m$ fasterq-dump -O maize_out/SRR765545 -o SRR765545.fastq -e 6 -f maize_out/SRR765545/SRR765545.sra\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 16:53:57\u001b[0m\n",
      "\u001b[92mTime taken:0:00:28\u001b[0m\n",
      "\u001b[93mStart:21-01-01 16:53:57\u001b[0m\n",
      "\u001b[96m$ trim_galore --cores 6 --paired -o maize_out/SRR765545 maize_out/SRR765545/SRR765545_1.fastq maize_out/SRR765545/SRR765545_2.fastq\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 16:54:43\u001b[0m\n",
      "\u001b[92mTime taken:0:00:46\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#create a Trimgalore object\n",
    "tg=qc.Trimgalore()\n",
    "sraObjects=[]\n",
    "for x in runs:\n",
    "    thisSraOb=sra.SRA(x,workingDir)\n",
    "    thisSraOb.trim(tg)\n",
    "    sraObjects.append(thisSraOb)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  STAR Alignment and transcript assembly using StringTie\n",
    "\n",
    "Now we will align the trimmed fastq files using STAR. pyrpipe provides the `Star` class via the `mapping` module to use STAR in python. We will create a `Star` object and pass it to the `align` function.\n",
    "\n",
    "We are providing the index as `workingDir+\"/starindex\"`. If this index doesn't exist pyrpipe will create one using the genome. Additional STAR parameters specified in the `./params/star.yaml` file will be loaded automatically.\n",
    "\n",
    "`./params/star.yaml` file contains:\n",
    "\n",
    "```\n",
    "--outFilterType : BySJout\n",
    "--runThreadN\": 6\n",
    "--outSAMtype: BAM SortedByCoordinate\n",
    "\n",
    "```\n",
    "\n",
    "**Note: It is recommended that users generate their index using appropriate parameters. Parameters to be used while building an index could be stored in star_index.yaml files and pyrpipe will automatically load them if building a new index.**\n",
    "\n",
    "To reduce the RAM consumption during generating of STAR index `--genomeChrBinNbits 5` option is added to `star_index.yaml`.\n",
    "\n",
    "To perform transcript assembly using stringtie, we create a `Stringtie` object.\n",
    "The `align()` and `assemble()` functions can be `chained` so we can write a `one-liner` to perform alignemnt and assembly.\n",
    "\n",
    "The `align()` method performs alignemnt and the resultant bam file is stored in the `SRA` object as the `bam_path` attribute. The `assemble()` function requires the `bam_path` attribute and uses it to perform transcript assembly using the provided `Assembler` object (stringtie in this example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parametrs can go into ./params/star.yaml\n",
    "star=mapping.Star(index=workingDir+\"/starindex\",genome=GENOME,threads=3) \n",
    "#create stringtie object\n",
    "st=assembly.Stringtie()\n",
    "gtfList=[]\n",
    "\n",
    "#combine align and assemble\n",
    "for x in sraObjects:\n",
    "    #align and assemble\n",
    "    x.align(star).assemble(st)\n",
    "    gtfList.append(x.gtf)   \n",
    "\n",
    "print(gtfList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows that a STAR index was generated first. Then, the options present in the `star.yaml` file were loaded and passed to the STAR command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lncRNA prediction using PLncPRO\n",
    "We will use [PLncPRO](https://github.com/urmi-21/PLncPRO) for prediction of lncRNAs. Currently, PLncPRO is not integrated into `pyrpipe` so we will use the `pyrpipe_engine` module directly to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyrpipe modules\n",
    "from pyrpipe import pyrpipe_engine as pe\n",
    "#install plncpro\n",
    "pe.execute_command(\"pip install plncpro\".split(),verbose=True,quiet=False,logs=False)\n",
    "#OR\n",
    "#!pip install plncpro\n",
    "\n",
    "\n",
    "genome=\"maize_data/Zea_mays.B73_RefGen_v4.dna.toplevel.1_10.fa\"\n",
    "model=\"monocot_model/monocot.model\"\n",
    "blastdb=\"uniprot/uniprotdb\"\n",
    "for i in range(len(gtfList)):\n",
    "    thisOb=sraObjects[i]\n",
    "    #first extract transcripts using gffread\n",
    "    tx_file=thisOb.location+\"/transcripts.fa\"\n",
    "    cmd=\"gffread -w \"+tx_file+\" -g maize_data/Zea_mays.B73_RefGen_v4.dna.toplevel.1_10.fa \"+gtfList[i]\n",
    "    pe.execute_command(cmd.split(\" \"),verbose=False,quiet=False,logs=True,objectid=thisOb.srr_accession,command_name=\"gffread\")\n",
    "    \n",
    "    #Optional step use biopython to filter transcripts by len\n",
    "    #out_file=thisOb.location+\"/transcripts_filter.fa\"\n",
    "    #output_handle = open(out_file, \"w\")\n",
    "    #for record in SeqIO.parse(tx_file, \"fasta\"):\n",
    "        # keep tx between 200 and 1000\n",
    "    #    if len(record)>=500 and len(record)<=1000:\n",
    "    #        #write to temp file\n",
    "    #        SeqIO.write(record, output_handle, \"fasta\")\n",
    "\n",
    "    \n",
    "    #run plncpro\n",
    "    outdir=thisOb.location+\"/plncpro_out\"\n",
    "    outfile=\"plncpro_predictions\"\n",
    "    cmd=\"plncpro predict -i \"+tx_file+\" -o \"+outdir+\" -p \"+outfile+\" -t 25 --min_len 200 -d \"+blastdb+\" -m \"+model+\" -v -r\"\n",
    "    pe.execute_command(cmd.split(),verbose=False,quiet=False,logs=True,objectid=thisOb.srr_accession,command_name=\"plncpro predict\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: Following commands are executed in shell, hence the ! before each command\n",
    "!pyrpipe_diagnostic.py report pyrpipe_logs/2020-01-22-18_14_47_pyrpipe.log\n",
    "!pyrpipe_diagnostic.py benchmark pyrpipe_logs/2020-01-22-18_14_47_pyrpipe.log\n",
    "!pyrpipe_diagnostic.py shell pyrpipe_logs/2020-01-22-18_14_47_pyrpipe.log\n",
    "!pyrpipe_diagnostic.py multiqc -o ./multiqc_report pyrpipe_logs/2020-01-22-18_14_47_pyrpipe.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
